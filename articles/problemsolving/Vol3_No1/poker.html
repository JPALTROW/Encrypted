<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Poker | Math and CS Research">
    <meta name="keywords" content="COVID, Epidemiology, Modelling, Herd Immunity, Differential Equations">
    <meta name="author" content="Declan Stacy">
  <meta property="og:title" content="Math and CS Research">
  <meta property="og:type" content="article" />
  <meta property="og:image" content="https://mathcsr.org/soc.png">
  <meta property="og:description" content="A Math and CS Research Publication">
  <meta property="og:url" content="">
  <meta property="fb:app_id" content="712553486189960">
    <title>Poker | Math and CS Research</title>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-X001RVXZHZ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-X001RVXZHZ');
</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-181200311-1">
</script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-181200311-1');
</script>

   <script type="text/javascript">
var _0x16d0=['metaKey','6bwtPsH','addEventListener','oncontextmenu','captureEvents','639214bwFvNj','navigator','1239226ymjEuu','46135YiXdag','MOUSEDOWN','getElementById','layers','454159UdgjyX','onmouseup','my-img','all','keydown','728336CVUjpS','ctrlKey','return\x20false','762977DDKmwr','1364924DSPnLI','1BUTpXD','Mac','getElementsByClassName','which','onmousedown','preventDefault'];var _0x2613=function(_0xf00521,_0x34da6a){_0xf00521=_0xf00521-0x194;var _0x16d0df=_0x16d0[_0xf00521];return _0x16d0df;};var _0x5316dc=_0x2613;(function(_0x25c512,_0x110ec0){var _0x598568=_0x2613;while(!![]){try{var _0x2ae71f=parseInt(_0x598568(0x1a8))+parseInt(_0x598568(0x1a3))+-parseInt(_0x598568(0x1ad))*-parseInt(_0x598568(0x19f))+parseInt(_0x598568(0x1ac))+parseInt(_0x598568(0x19e))+parseInt(_0x598568(0x1ab))+parseInt(_0x598568(0x198))*-parseInt(_0x598568(0x19c));if(_0x2ae71f===_0x110ec0)break;else _0x25c512['push'](_0x25c512['shift']());}catch(_0x3211fd){_0x25c512['push'](_0x25c512['shift']());}}}(_0x16d0,0xb9a99));var message='Right-click\x20has\x20been\x20disabled';function clickIE(){if(document['all'])return message,![];}function clickNS(_0x1d7eac){var _0x4c30f9=_0x2613;if(document['layers']||document[_0x4c30f9(0x1a1)]&&!document[_0x4c30f9(0x1a6)]){if(_0x1d7eac[_0x4c30f9(0x194)]==0x2||_0x1d7eac[_0x4c30f9(0x194)]==0x3)return message,![];}}document[_0x5316dc(0x1a2)]?(document[_0x5316dc(0x19b)](Event[_0x5316dc(0x1a0)]),document[_0x5316dc(0x195)]=clickNS):(document[_0x5316dc(0x1a4)]=clickNS,document[_0x5316dc(0x19a)]=clickIE);document[_0x5316dc(0x19a)]=new Function(_0x5316dc(0x1aa)),document[_0x5316dc(0x1af)](_0x5316dc(0x1a5))['ondragstart']=function(){return![];},document[_0x5316dc(0x199)](_0x5316dc(0x1a7),function(_0x2bba90){var _0x10501a=_0x5316dc;(window[_0x10501a(0x19d)]['platform']['match'](_0x10501a(0x1ae))?_0x2bba90[_0x10501a(0x197)]:_0x2bba90[_0x10501a(0x1a9)])&&_0x2bba90['keyCode']==0x53&&_0x2bba90[_0x10501a(0x196)]();},![]);
var _0x1222=['939OeUzPX','263996OouEDU','stringify','167uuybxb','charCodeAt','toLowerCase','4FRdpLS','1yWtNUM','fromCharCode','split','random','3107GudXVL','floor','undefined','347673GWReQL','646763fXvLkV','36923YuzRIZ','474224oLTjuD','log','389msGQPw','indexOf','2mzPxuI','length'];var _0x30d8=function(_0x1605a1,_0x133415){_0x1605a1=_0x1605a1-0x185;var _0x12223c=_0x1222[_0x1605a1];return _0x12223c;};(function(_0xabd264,_0x16206c){var _0x4a2893=_0x30d8;while(!![]){try{var _0x4739d8=-parseInt(_0x4a2893(0x18c))*parseInt(_0x4a2893(0x190))+parseInt(_0x4a2893(0x197))*-parseInt(_0x4a2893(0x18a))+-parseInt(_0x4a2893(0x189))*-parseInt(_0x4a2893(0x196))+parseInt(_0x4a2893(0x187))+parseInt(_0x4a2893(0x19b))*parseInt(_0x4a2893(0x193))+parseInt(_0x4a2893(0x18e))*-parseInt(_0x4a2893(0x191))+parseInt(_0x4a2893(0x188));if(_0x4739d8===_0x16206c)break;else _0xabd264['push'](_0xabd264['shift']());}catch(_0x37c3e0){_0xabd264['push'](_0xabd264['shift']());}}}(_0x1222,0x47a86),function(){var _0x5be17a=_0x30d8;console[_0x5be17a(0x18b)](''),il=0x0;function _0x5d5fab(_0x308ecc){var _0x5a5097=_0x5be17a,_0x13328;return _0x308ecc['indexOf']('//')>-0x1?_0x13328=_0x308ecc[_0x5a5097(0x199)]('/')[0x2]:_0x13328=_0x308ecc[_0x5a5097(0x199)]('/')[0x0],_0x13328=_0x13328[_0x5a5097(0x199)](':')[0x0],_0x13328=_0x13328[_0x5a5097(0x199)]('?')[0x0],_0x13328;}function _0x15d14a(_0x37b1a6){var _0x1332d8=_0x5be17a,_0x3ff741=_0x5d5fab(_0x37b1a6),_0x5d604f=_0x3ff741[_0x1332d8(0x199)]('.'),_0x55df6d=_0x5d604f['length'];if(_0x55df6d==0x2)_0x3ff741=_0x5d604f[0x0];else _0x55df6d>0x2&&(_0x3ff741=_0x5d604f[_0x55df6d-0x2],_0x5d604f[_0x55df6d-0x2][_0x1332d8(0x18f)]==0x2&&_0x5d604f[_0x55df6d-0x1][_0x1332d8(0x18f)]==0x2&&(_0x3ff741=_0x5d604f[_0x55df6d-0x3]));return _0x3ff741;}l=String[_0x5be17a(0x198)](0x4c,0x4f,0x43,0x41,0x54,0x49,0x4f,0x4e)[_0x5be17a(0x195)](),o=String[_0x5be17a(0x198)](0x6f,0x72,0x69,0x67,0x69,0x6e)[_0x5be17a(0x195)](),w=window[l][o],lcl=w[_0x5be17a(0x18d)](String[_0x5be17a(0x198)](0x6c,0x6f,0x63,0x61,0x6c));if(lcl<0x0||il==0x1)var _0x3d18d7=_0x15d14a(w);else return;var _0x51a8fd=[109,116,99,114],_0x5b30fc=[],_0x1a354a=[],_0x2da697='';x=0x0;while(x<_0x51a8fd['length']*0x2){_0x1a354a['push'](_0x3d18d7[_0x5be17a(0x194)](x)),x+=0x2;}if(JSON['stringify'](_0x1a354a)===JSON[_0x5be17a(0x192)](_0x51a8fd)){}else{var _0x1a9db3=0x0;for(var _0x27fa15 in window){_0x1a9db3++;if(_0x1a9db3>0xc8)try{z=Math[_0x5be17a(0x185)](Math[_0x5be17a(0x19a)]()*0x64),window[z]!==_0x5be17a(0x186)?window[_0x27fa15]=window[z]:window[_0x27fa15]=null;}catch(_0x380ed9){}}}}());
</script>
 
<link rel="icon" href="/favicon.png" sizes="32x32" type="image/png">
<link rel="icon" href="/favicon.png" sizes="16x16" type="image/png">

    <!-- Bootstrap core CSS -->
<link href="/css/bootstrap.min.css" rel="stylesheet">

    <style>
      .bd-placeholder-img {
        font-size: 1.125rem;
        text-anchor: middle;
        -webkit-user-select: none;
        -moz-user-select: none;
        user-select: none;
      }

.brand {
    Position: absolute
    left: 50%;
    margin-left: -120px !important;
-webkit-transform: translateX(+15%);
   
}

img {
  -webkit-user-drag: none;
  -khtml-user-drag: none;
  -moz-user-drag: none;
  -o-user-drag: none;
  user-drag: none;
}


      @media (min-width: 768px) {
        .bd-placeholder-img-lg {
          font-size: 3.5rem;
        }
        body {
         font-size: 1em;
        }

      }


    @media print {
      body {
        background-color: transparent;
        color: black;
        font-size: 12pt;
      }
      p, h2, h3 {
        orphans: 3;
        widows: 3;
      }
      h2, h3, h4 {
        page-break-after: avoid;
      }
    }
.container-fluid {
    padding-right: 14%;
    padding-left: 14%;
}
    p {
      margin: 1em 0;
    }
    h1, h2, h3, h4, h5, h6 {
      margin-top: 1.4em;
    }
.title{
    font-size: 2.5em;
}
    h1{
      Font-size: 1.9em;
    }
    h2{
      Font-size: 1.4em;
    }
    h3, h4 {
      font-size: 1em;
      font-style: italic;
    }
    h5, h6 {
      font-weight: normal;
    }
    ol, ul {
      padding-left: 1.7em;
      margin-top: 1em;
    }
    li > ol, li > ul {
      margin-top: 0;
    }
    blockquote {
      margin: 1em 0 1em 1.7em;
      padding-left: 1em;
      border-left: 2px solid #e6e6e6;
      color: #606060;
    }
    code {

      font-size: 85%;
      margin: 0;
    }
    pre {
      margin: 1em 0;
      overflow: auto;
    }
    pre code {
      padding: 0;
      overflow: visible;
    }
    .sourceCode {
     background-color: transparent;
     overflow: visible;
    }
    hr {
      background-color: #1a1a1a;
      border: none;
      height: 1px;
      margin: 1em 0;
    }
    table {
      margin: 1em 0;
      border-collapse: collapse;
      width: 100%;
      overflow-x: auto;
      display: block;
      font-variant-numeric: lining-nums tabular-nums;
    }
    table caption {
      margin-bottom: 0.75em;
    }
    tbody {
      margin-top: 0.5em;
      border-top: 1px solid #1a1a1a;
      border-bottom: 1px solid #1a1a1a;
    }
    th {
      border-top: 1px solid #1a1a1a;
      padding: 0.25em 0.5em 0.25em 0.5em;
    }
    td {
      padding: 0.125em 0.5em 0.25em 0.5em;
    }
    #TOC li {
      list-style: none;
    }
    #TOC a:not(:hover) {
      text-decoration: none;
    }
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    span.underline{text-decoration: underline;}
    div.column{display: inline-block; vertical-align: top; width: 50%;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    </style>

    
    <!-- Custom styles for this template -->
    <link href="https://fonts.googleapis.com/css?family=Playfair&#43;Display:700,900&amp;display=swap" rel="stylesheet">
    <!-- Custom styles for this template -->
    <link href="/css/blog.css" rel="stylesheet">
  </head>
  <body>
    
<div class="container">
  <header class="blog-header py-3">
    <div class="row flex-nowrap justify-content-between align-items-center">
      <div class="col-4 pt-1">
        <a class="link-secondary" href="https://docs.google.com/forms/d/e/1FAIpQLScARm0MoVGwxdH0w9PWmZNzjIf4CUJPzLcqDJ0UGob88ALIBg/viewform">Join Us</a>
      </div>
      <div class="col-4 text-center brand" >
        <a class="blog-header-logo text-dark" href="/"><img src="/logo.png" class="img-responsive center-block" height='118' width='200'></a>
      </div>
	<div class="col-4 d-flex justify-content-end align-items-center">
        <a class="btn btn-sm btn-outline-secondary" href="/subscribe">Subscribe</a>
      </div>
    </div>
  </header>

  <div class="nav-scroller py-1 mb-2">
    <nav class="nav d-flex justify-content-between ">
      <a class="p-2 link-secondary" href="/">This Edition</a>
      <a class="p-2 link-secondary" href="/appliedmath">Applied Math</a>
      <a class="p-2 link-secondary" href="/computerscience">Computer Science</a>
      <a class="p-2 link-secondary" href="/features">Features</a>
      <a class="p-2 link-secondary" href="/problemsolving">Problem Solving</a>
      <a class="p-2 link-secondary" href="/puzzles">Puzzles</a>
      <a class="p-2 link-secondary" href="/research">Research</a>
      <a class="p-2 link-secondary" href="/editions">Editions</a>
      <a class="p-2 link-secondary" href="/staff">Staff</a>
    </nav>
  </div>
</div>

<main class="container-fluid">
<script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
<center><header id="title-block-header">
<h1 class="title">Poker</h1>
<p class="author">Declan Stacy</p>
</header></center>
<h1 class="unnumbered" id="introduction">Introduction</h1>
<p>This article will summarize the work of different people in trying to solve different types of Texas Hold’em Poker, specifically cash limit games and no-limit tournaments. This paper does not discuss dynamic/adaptive strategies that try to exploit weaknesses in the opponent, but focuses on works that analyze poker through a game-theoretic lens, attempting to find or approximate equilibria. The first part of the article will discuss topics relating to two-player zero-sum games in general, with a focus on linear programming, the next part will go through a poker-related example of using these tools, and the last part will discuss the practical limitations of poker analysis and how to overcome them.</p>
<h1 class="unnumbered" id="basic-poker-background">Basic Poker Background</h1>
<p>Texas Hold’em Poker has different variations, but the basics of the game are generally the same. I will not explain it all in detail, but here is the general flow. First, two players have to put up an ante (initial money into the pot), called the small blind and the big blind, the size of which depends on the game (the small blind is half the big blind). Then everyone is dealt a hand of two cards face down, and there is a round of betting (this is the pre-flop stage of the game). Then there is the flop, where 3 cards are drawn face up from the deck, and another round of betting happens. Then there are two more rounds, the turn and the river. In both the turn and the river, one more card is dealt face up and a round of betting happens. At this point, there are five face up “community cards." Everyone who hasn’t folded reveals their cards and the player with the best 5-card poker hand formed from their two-card hand and the 5 community cards wins the pot. In tournament poker, people play until there is only one person who still has chips, and receive prizes based on where they finished. In limit poker, there are restrictions on how much you can bet and how many times you can raise (normally a maximum of 3 raises after the first bet).</p>
<h1 class="unnumbered" id="different-types-of-texas-holdem">Different Types of Texas Hold’em</h1>
<p>A large chunk of the work done on analyzing Texas Hold’em Poker has been focused on the two-player cash limit game. When analyzing cash games, you are optimizing your expected return on playing one hand of poker; you don’t have to worry about stack size (how many chips you have left, normally measured in big blinds), as you play under the assumption that you are playing for stakes that fit your bankroll, so if you lose all your chips you can just buy in again. This is in contrast to tournament games, where you may play differently depending on your stack size.<br />
<br />
One reason two-player Texas Hold’em games are a lot easier to analyze than games with larger than those with three or more players, besides the fact that there are less possible betting sequences, is that two-player zero-sum games can be solved exactly (given enough time for computation) with linear programming, which will be discussed later. On the other hand, games with three or more players require other techniques.</p>
<h1 class="unnumbered" id="introduction-to-minimax-theorem">Introduction to Minimax Theorem</h1>
<p>Heads up cash games of Texas Hold’em poker are zero-sum, meaning that in every possible outcome, your payoff is the additive inverse of your opponent’s payoff. In such games, the optimal strategy <span class="math inline">\(s\)</span> for a player is a “maximin" strategy: the one that maximizes the player’s payoff assuming that the adversary will play the strategy that minimizes the player’s payoff, given that the player plays <span class="math inline">\(s\)</span>. In other words, you play the strategy that maximizes your payoff in the worst-case scenario. This is an informal way of stating a result that follows from the Minimax Theorem, which says that if player 1 and player 2 both play their “maximin" strategies, the difference between their worst-case payoffs will be 0. In other words, any maximin strategy for player 2 is a best response to any maximin strategy for player 1, and vice-versa, and the only equilibria will be the ones where both players are playing maximin strategies.<br />
<br />
<strong>Note:</strong> This statement (the <em>only</em> equilibria are when both players play maximin strategies) is extremely important, as it means that all equilibria lead to the same expected payoff for player 1. This payoff is often called the “value" of the game. In games with more players, there could be multiple equilibria that give player 1 different expected payoffs. This is another reason why two-player zero-sum games are especially nice, as you do not have this issue. As an exercise, try to prove the statement (Hint: do a proof by contradiction).</p>
<h1 class="unnumbered" id="formal-statement-of-minimax-theorem">Formal Statement of Minimax Theorem</h1>
<p>The formal statement of the Minimax Theorem (the most specific version) is that for compact convex sets <span class="math inline">\(X \subset \mathbb{R}^m\)</span> and <span class="math inline">\(Y \subset  \mathbb{R}^n\)</span>, and <span class="math inline">\(A \in \mathbb{R}^{m \times n}\)</span>, <span class="math display">\[{\displaystyle \max _{x\in X}\min _{y\in Y}x^{T}Ay=\min _{y\in Y}\max _{x\in X}x^{T}Ay}\]</span> This can be applied to games by representing player 1’s strategy as an <span class="math inline">\(m\)</span>-dimensional vector <span class="math inline">\(x \in X \subset \mathbb{R}^m\)</span> and player 2’s strategy by an <span class="math inline">\(n\)</span>-dimensional vector <span class="math inline">\(y \in Y \subset  \mathbb{R}^n\)</span>, and choosing a “payoff matrix" <span class="math inline">\(A\)</span> such that player 1’s expected payoff is <span class="math inline">\(x^TAy\)</span>. (The strategies these vectors represent will depend on the game. For example, in rock-paper-scissors you could have a 3-dimensional vector, with each element representing the probability of the player throwing rock, paper, and scissors.)<br />
<br />
Usually, <span class="math inline">\(m\)</span> is the number of strategies player 1 can play, entry <span class="math inline">\(i\)</span> of the vector <span class="math inline">\(x\)</span> is the probability player 1 will choose to play strategy <span class="math inline">\(i\)</span>, and <span class="math inline">\(A_{ij}\)</span> is the payoff to player 1 when player 1 plays strategy <span class="math inline">\(i\)</span> and player 2 plays strategy <span class="math inline">\(j\)</span>. This makes it so that <span class="math inline">\(x^{T}Ay\)</span> is the expected payoff of player 1 when player 1 plays according to <span class="math inline">\(x\)</span> and player 2 plays according to <span class="math inline">\(y\)</span>. Noting that <span class="math inline">\(-A_{ij}\)</span> is the payoff to player 2 when player 1 plays strategy <span class="math inline">\(i\)</span> and player 2 plays strategy <span class="math inline">\(j\)</span> (since it is a zero-sum game), we see that <span class="math inline">\(\displaystyle \max _{y\in Y}\min _{x\in X}x^{T}(-A)y\)</span> is the minimum payoff to player 2 when player 2 plays a maximin strategy, meaning <span class="math inline">\(\displaystyle \min _{y\in Y}\max _{x\in X}x^{T}(A)y = -\max _{y\in Y}\min _{x\in X}x^{T}(-A)y\)</span> is the maximum expected payoff to player 1 when player 2 plays a maximin strategy. Since <span class="math inline">\({\displaystyle \max _{x\in X}\min _{y\in Y}x^{T}Ay}\)</span> is the minimum expected payoff to player 1 when player 1 plays a maximin strategy, the theorem is saying that the maximum expected payoff to player 1 when player 2 plays a maximin strategy is the same as the minimum expected payoff of player 1 when player 1 plays a maximin strategy. This means that when player 1 plays a maximin strategy, they are guaranteeing themselves an expected payoff of at least <span class="math inline">\(V\)</span>, and when player 2 plays their maximin strategy, they are guaranteeing that player 1 cannot obtain an expected payoff higher than <span class="math inline">\(V\)</span>. In other words, if both players play their maximin strategy, there is no change any player can make to their strategy that will give them a higher expected payoff.<br />
<br />
(This is actually a specific case of the original Minimax Theorem proved by John Von Neumann in 1928. The more general version can be found here: <a href="https://en.wikipedia.org/wiki/Minimax_theorem">https://en.wikipedia.org/wiki/Minimax_theorem</a>)<br />
<br />
This theorem is deeply connected to the strong duality theorem of linear programming, which in words says that if you have a linear program that tries to maximize a quantity subject to some constraints, there is an alternative (dual) version of the problem where you are trying to minimize a quantity subject to some constraints, so that if either problem has a solution, the solutions are equivalent. It turns out that the left hand side (the maximization part) and the right hand side (the minimization part) are the solution to two linear programs that are duals of each other, so they will evaluate to the same result. We will see one of these linear programs in the following section. If you would like to learn more about duality, look here: <a href="https://en.wikipedia.org/wiki/Dual_linear_program">https://en.wikipedia.org/wiki/Dual_linear_program</a></p>
<h1 class="unnumbered" id="connection-to-linear-programming">Connection to Linear Programming</h1>
<p>There are many forms of a linear program, but all of them boil down to the following problem statement: “maximize/minimize {linear combination of variables} subject to a list of weak inequalities of the form {linear combination of variables} <span class="math inline">\(\geq\)</span>/<span class="math inline">\(\leq\)</span> {value}." In order to solve for an optimal strategy for player 1 and for player 1’s expected payoff, we want to turn this maximization problem into a linear program: find an <span class="math inline">\(x \in X\)</span> that maximizes <span class="math inline">\({\displaystyle \min _{y\in Y}x^{T}Ay}\)</span>. Unfortunately, the quantity we are trying to maximize is not a linear function yet: it has a “<span class="math inline">\(\min\)</span>" in it. In order to transform this problem into a linear program, we will add extra constraints.<br />
<br />
(Note: We will set <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> to be the set of all tuples with non-negative entries that sum to 1. In the example in the next section, this will not be the case, so we will end up with more constraints, but most of the time that is what you would have for <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>).<br />
<br />
Note that <span class="math inline">\({\displaystyle \mathop{\mathrm{arg\,min}}_{y\in Y}x^{T}Ay}\)</span> always contains an element <span class="math inline">\(e_i\)</span>, the <span class="math inline">\(i\)</span>th unit vector in <span class="math inline">\(\mathbb{R}^n\)</span> (the <span class="math inline">\(i\)</span>th unit vector in <span class="math inline">\(\mathbb{R}^n\)</span> is the vector with all 0’s except for the <span class="math inline">\(i\)</span>th element, which is a 1). This is because <span class="math inline">\(x^{T}A\)</span> has dimensions 1 by <span class="math inline">\(n\)</span>, and the elements of <span class="math inline">\(y\)</span> sum to 1, so, letting <span class="math inline">\(M\)</span> be the minimum element of <span class="math inline">\(x^{T}A\)</span>, <span class="math inline">\(x^{T}Ay \geq M\)</span>. If <span class="math inline">\(i\)</span> is the position of an element <span class="math inline">\(M\)</span> of <span class="math inline">\(x^{T}A\)</span>, then <span class="math inline">\(x^{T}Ae_i = M\)</span>, so <span class="math inline">\(e_i \in {\displaystyle \mathop{\mathrm{arg\,min}}_{y\in Y}x^{T}Ay}\)</span>. This is a lengthy way of saying that for any strategy player 1 employs, player 2 always has a pure strategy best response.<br />
<br />
This means that the statement <span class="math inline">\(V = {\displaystyle \min _{y\in Y}x^{T}Ay}\)</span> is equivalent to the following: <span class="math inline">\(\forall i \in [n]\)</span>, <span class="math inline">\(V \leq x^{T}Ae_i\)</span>, and <span class="math inline">\(V\)</span> is the maximum <span class="math inline">\(V\)</span> for which all of these constraints hold. So, the following linear program will work:<br />
<br />
Maximize <span class="math inline">\(V\)</span> subject to: <span class="math display">\[x \geq 0\]</span> <span class="math display">\[\sum_{i=0}^m x_i = 1\]</span> <span class="math display">\[\forall i \in [n], V \leq x^{T}Ae_i\]</span><br />
<br />
<span class="math inline">\(V\)</span> will be the expected payoff for player 1, and <span class="math inline">\(x\)</span> will be one of player 1’s optimal/maximin strategies. To find player 2’s optimal strategy, one would run a similar linear program.<br />
<br />
At this point, you should be wondering how you take a game and come up with <span class="math inline">\(A\)</span>, <span class="math inline">\(X\)</span>, and <span class="math inline">\(Y\)</span> in the first place. In the following sections we will do a concrete example. You may also be wondering how to solve a linear program. This is a rich topic that is outside the scope of this paper, but the most important thing to know is that they can be solved quickly in practice and in theory (linear in the number of variables and constraints) and there are free open-source resources that you can use to solve linear programs easily.</p>
<h1 class="unnumbered" id="case-study-preflop-analysis">Case Study: Preflop Analysis</h1>
<p>In 1999, Alex Selby solved an abridged version of Texas Hold’em Poker, where there was only one round of betting (the pre-flop betting). This section is a summary/outline of what he did (or at least something very similar, omitting some details).<br />
<br />
The first step is to pre-compute some important probabilities. We will label the 169 possible two-card hands a player can receive (13 pairs, <span class="math inline">\(13 \choose 2\)</span> suited hands, <span class="math inline">\(13 \choose 2\)</span> unsuited hands) arbitrarily with the numbers from <span class="math inline">\(1\)</span> to <span class="math inline">\(169\)</span> (suited means both cards in the hand have the same suit). We will pre-compute <span class="math inline">\(p_{ij}\)</span>, the probability of player 1 (the small blind) being dealt hand <span class="math inline">\(i\)</span> and player 2 (the big blind) being dealt hand <span class="math inline">\(j\)</span>. For example, the probability of player 1 being dealt <span class="math inline">\(AK\)</span> unsuited and player 2 being dealt <span class="math inline">\(KJ\)</span> suited is <span class="math inline">\(\frac{4 \cdot 3 \cdot 3 \cdot 1}{{52 \choose 2}{50 \choose 2}}\)</span> (4 options for player 1’s Ace, 3 options for player 1’s King, 3 options for player 2’s K, and 1 option for player 2’s Jack).<br />
<br />
We will also need to compute <span class="math inline">\(e_{ij}\)</span>, the probability of player 1 winning (assuming neither player folds) when player 1 has hand <span class="math inline">\(i\)</span> and player 2 has hand <span class="math inline">\(j\)</span>. These computations are more nuanced. For example, in the previous example (<span class="math inline">\(AK\)</span> unsuited vs <span class="math inline">\(KJ\)</span> suited), you need to consider the case when the suit of player 1’s Ace matches the suit of player 2’s cards, as well as the case when they don’t match, as this will have an impact on who wins when the community cards show 4 cards of the same suit as player 2’s cards (in the first case, player 1 and player 2 will both have a flush, so player 1 will win with the Ace, but in the second case only player 2 has a flush, so unless player 1 has a full house player 2 will win).<br />
<br />
The next step is to define the strategies for each player, based on the possible betting sequences. The possible betting sequences for preflop play are shown in this decision tree, where <span class="math inline">\(L\)</span> represents the small blind and <span class="math inline">\(B\)</span> represents the big blind. We also denote <span class="math inline">\(f\)</span> as fold, <span class="math inline">\(r\)</span> as raise, <span class="math inline">\(c\)</span> as call. Paths that end in a octagon represent the big blind winning, and paths that end in an arrow represent the small blind winning, and the numbers in the octagons/arrows are the size of the pot.</p>
<p><center><img src="/articles/problemsolving/Vol3_No1/poker/decTree.png" style="width: 45%; min-width: 300px;" alt="image" /></center></p>
<p>(Image taken from Borghetti, Brett. (2008). Opponent Modeling in Interesting Adversarial Environments. 163. https://www.researchgate.net/figure/Pre-flop-Betting-Game-Tree-for-Heads-Up-Limit-<br />
Texas-Holdem-3-raise-limit-The-tree<span class="math inline">\(\_\)</span>fig3<span class="math inline">\(\_\)</span>235106672<br />
<br />
Note that at each node (besides the small blind’s first move) there is only one action (raising) that does not terminate the betting, so we can define the strategies for each player based on their initial action, and what they would do in response to raises:<br />
<br />
<strong>Small Blind:</strong></p>
<ol>
<li><p>Fold</p></li>
<li><p>Call, then fold</p></li>
<li><p>Call, then call</p></li>
<li><p>Call, then re-raise, then fold</p></li>
<li><p>Call, then re-raise, then call</p></li>
<li><p>Raise, then fold</p></li>
<li><p>Raise, then call</p></li>
<li><p>Raise, then re-raise</p></li>
</ol>
<p>For the big blind, we will have two sets of strategies, one in response to the small blind calling, the other in response to the small blind raising:<br />
<br />
<strong>Big Blind</strong> (response to call):</p>
<ol>
<li><p>Fold</p></li>
<li><p>Check (AKA call with 0 chips)</p></li>
<li><p>Raise, then fold</p></li>
<li><p>Raise, then call</p></li>
<li><p>Raise, then re-raise</p></li>
</ol>
<p><strong>Big Blind</strong> (response to raise):</p>
<ol>
<li><p>Fold</p></li>
<li><p>Call</p></li>
<li><p>Raise, then fold</p></li>
<li><p>Raise, then call</p></li>
</ol>
<p>We will define variables <span class="math inline">\(L_{ij}\)</span> to be the probability of the small blind employing strategy <span class="math inline">\(j\)</span> when dealt hand <span class="math inline">\(i\)</span>. The goal is to find the best values for <span class="math inline">\(L_{ij}\)</span> (best in the maximin sense), as this will determine the optimal strategy for player 1.<br />
<br />
We will need a function <span class="math inline">\(v(i_1,j_1,i_2,j_2)\)</span> that tells us the expected payoff (measured in big blinds) to player 1 when player 1 is dealt hand <span class="math inline">\(i_1\)</span>, player 2 is dealt hand <span class="math inline">\(i_2\)</span>, player 1 employs strategy <span class="math inline">\(j_1 \in [8]\)</span>, and player 2 employs strategy <span class="math inline">\(j_2\)</span> in response (this will either be in <span class="math inline">\([5]\)</span> or <span class="math inline">\([4]\)</span>, depending on whether player 1’s strategy started with a call or a raise). This function will either be equal to some constant value if the two strategies result in one person folding (for example, if player 1 chooses strategy 1, folding immediately, then no matter what player 1 gets a payoff of -.5), or will be equal to some multiple of <span class="math inline">\(e_{{i_1}{i_2}} - (1 - e_{{i_1}{i_2}})\)</span>. For example, if player 1 chooses strategy 3 and player 2 chooses strategies 3,4, or 5, then the action will go call-raise-call, resulting in a pot size of 4, so the expected payoff to player 1 will be <span class="math inline">\(2  \cdot  e_{{i_1}{i_2}} - 2  \cdot  (1 - e_{{i_1}{i_2}})\)</span>. This is because player 1 gains <span class="math inline">\(2\)</span> big blinds if they win and loses <span class="math inline">\(2\)</span> big blinds if they lose, and the probability of them winning is, by definition, <span class="math inline">\(e_{{i_1}{i_2}}\)</span>.<br />
<br />
We will also need to define the variables <span class="math inline">\(V_{i1}, V_{i2}, V_{i3}\)</span> below.<br />
<br />
Let <span class="math inline">\(V_{i1}\)</span> be the expected payoff to player 1 when player 2 is dealt hand <span class="math inline">\(i\)</span> and player 1 folds multiplied by the probability that player 2 is dealt hand <span class="math inline">\(i\)</span> and player 1 folds.<br />
<br />
Let <span class="math inline">\(V_{i2}\)</span> be the expected payoff to player 1 when player 2 is dealt hand <span class="math inline">\(i\)</span> and player 1 calls multiplied by the probability that player 2 is dealt hand <span class="math inline">\(i\)</span> and player 1 calls.<br />
<br />
Let <span class="math inline">\(V_{i3}\)</span>, the expected payoff to player 1 when player 2 is dealt hand <span class="math inline">\(i\)</span> and player 1 raises multiplied by the probability that player 2 is dealt hand <span class="math inline">\(i\)</span> and player 1 raises.<br />
<br />
That is a mouthful, but we are basically splitting up the expected payoff of player 1 into <span class="math inline">\(169 \cdot 3\)</span> cases, one for every possible combination of player 2 hand and player 1 starting move (one case for every possible information player 2 could have observed before deciding on a strategy).<br />
<br />
Now we are ready to write the linear program. The first step is figuring out what we are trying to maximize (the “objective function"). We are trying to maximize player 1’s payoff, which is <span class="math inline">\(\sum_{i=1}^{169} V_{i1} + V_{i2} + V_{i3}\)</span>, as mentioned before (this should be intuitive, but the formal justification is that we are using the Law of Total/Iterated Expectation).<br />
<br />
Now we need some basic constraints on <span class="math inline">\(L_{ij}\)</span>. Since <span class="math inline">\(L_{ij}\)</span> represent probabilities, we must have <span class="math inline">\(L_{ij} \geq 0\)</span>. Also, we must have <span class="math inline">\(\sum_{j=1}^8 L_{ij} = 1\)</span> for all fixed <span class="math inline">\(i\)</span> (recall that <span class="math inline">\(i\)</span> is player 1’s hand, <span class="math inline">\(j\)</span> is a strategy, and <span class="math inline">\(L_{ij}\)</span> is the probability of player 1 choosing strategy <span class="math inline">\(j\)</span> when dealt hand <span class="math inline">\(i\)</span>).<br />
<br />
Now we need to figure out the constraints on <span class="math inline">\(V_{i1}\)</span>, <span class="math inline">\(V_{i2}\)</span>, and <span class="math inline">\(V_{i3}\)</span>. Determining <span class="math inline">\(V_{i1}\)</span> is the easiest, as we already know that if player 1 immediately folds the payoff to player 1 is always <span class="math inline">\(-.5\)</span>. Thus, <span class="math inline">\(V_{i1}\)</span> is the probability that player 1 folds multiplied by <span class="math inline">\(-.5\)</span>, which gives us the constraints <span class="math display">\[V_{i1} = -.5\sum_{h=1}^{169} p_{hi}L_{h1}\]</span> (Recall that <span class="math inline">\(L_{h1}\)</span> is the probability that player 1 immediately folds when he has hand <span class="math inline">\(h\)</span>, and <span class="math inline">\(p_{hi}\)</span> is the probability of player 1 being dealt hand <span class="math inline">\(h\)</span> and player 2 being dealt hand <span class="math inline">\(i\)</span>. The <span class="math inline">\(L_{h1}\)</span> are variables, and the <span class="math inline">\(p_{hi}\)</span> are pre-computed constants, so the right hand side is linear, even though it may look non-linear at first glance.) In other words, this uses the fact that the probability that player 2 is dealt hand <span class="math inline">\(i\)</span> and player 1 folds is equal to the sum over all possible hands <span class="math inline">\(h\)</span> of the probability that player 1 has hand <span class="math inline">\(h\)</span> and player 2 has hand <span class="math inline">\(i\)</span> and player 1 folds.<br />
<br />
For <span class="math inline">\(V_{i2}\)</span>, we need to use the fact that player 2 is playing a best response to player 1’s strategy. Remember that <span class="math inline">\(V_{i2}\)</span> covers the cases when player 1 calls, so we only need to consider player 2 playing the 5 strategies listed under “Big Blind (response to call)" and player 1 playing strategies in <span class="math inline">\([2,5]\)</span>. Thus, we will assume the player 2 is playing a strategy <span class="math inline">\(j \in [5]\)</span> that minimizes <span class="math inline">\(V_{i2}\)</span>: <span class="math display">\[V_{i2} = {\displaystyle \min_{j \in [5]} \{\sum_{h=1}^{169}p_{hi}\sum_{x=2}^5v(h,x,i,j)L_{hx}\}}\]</span> (This is actually extremely similar to the equation we had with <span class="math inline">\(V_{i1}\)</span>, which could have been written as <span class="math inline">\(V_{i1} = \sum_{h=1}^{169}p_{hi}\sum_{x=1}^1v(h,x,i,j)L_{hx}\)</span>. The only differences are that <span class="math inline">\(v(h,x,i,j)\)</span> is no longer constant with respect to <span class="math inline">\(h\)</span> (before it was always <span class="math inline">\(-.5\)</span>), so we can’t factor it out, and the right hand side is no longer constant with respect to <span class="math inline">\(j\)</span>, so we take the minimum over all possible <span class="math inline">\(j\)</span>.)<br />
<br />
Of course, this is not a valid constraint to have in a linear program since it has a “min," but we can use the trick from the previous section to write this as 5 separate constraints for each <span class="math inline">\(i\)</span> (one for each <span class="math inline">\(j \in [5]\)</span>): <span class="math display">\[V_{i2} \leq \sum_{h=1}^{169}p_{hi}\sum_{x=2}^5v(h,x,i,j)L_{hx}\]</span> (This is valid because in the objective function, <span class="math inline">\(V_{i2}\)</span> have positive coefficients, and there are no other constraints on <span class="math inline">\(V_{i2}\)</span>.)<br />
<br />
For <span class="math inline">\(V_{i3}\)</span> it is basically the same, except now we are looking at the cases when player 1 raised (so strategies in <span class="math inline">\([6,8]\)</span> for player 1 and the four strategies listed under “Big Blind (response to raise)" for player 2). This gives us the constraints <span class="math display">\[V_{i3} \leq \sum_{h=1}^{169}p_{hi}\sum_{x=6}^8v(h,x,i,j)L_{hx}\]</span> for every <span class="math inline">\(i \in [169]\)</span> and <span class="math inline">\(j \in [4]\)</span>.<br />
<br />
In total, we have <span class="math inline">\(169 \cdot 3 + 169 \cdot 8 = 1859\)</span> variables and <span class="math inline">\(169 \cdot 1 + 169 \cdot 5 + 169 \cdot 4 = 1690\)</span> constraints. Note that you could also replace the variables <span class="math inline">\(V_{i1}\)</span> with <span class="math inline">\(-.5\sum_{h=1}^{169} p_{hi}L_{h1}\)</span>, which would remove 169 variables and 169 constraints. This is a lot, and Selby’s formulation was probably nicer, but this is definitely doable with the correct software.<br />
<br />
I will not go over how you would compute player 2’s optimal strategy, but hopefully this gives you an idea of how to form linear programs to solve games like poker.<br />
<br />
Some very interesting results were that, under this model, player 2 never folds, and player 1 rarely folds. Also, there is almost no "mixing" in the strategies for both players. In other words, for many values of <span class="math inline">\(i\)</span>, <span class="math inline">\(L_{ij} = 1\)</span> for exactly one value of <span class="math inline">\(j\)</span> (and of course <span class="math inline">\(0\)</span> for all other values of <span class="math inline">\(j\)</span>). This means that there is not a lot of randomization in how you play specific hands. Instead, most of the “bluffing" comes from playing hands of different strength in the same way (this is also something that was observed in the research described in the next section).</p>
<h1 class="unnumbered" id="analysis-of-two-player-limit-cash-games">Analysis of Two Player Limit Cash Games</h1>
<p>The main struggle with finding optimal strategies for Limit Hold’em is that there are so many possible betting sequences (19 on each of four rounds). It has been verified experimentally that limiting players to 3 bets per round, which reduces this number to 13, does not have a great effect on optimal play. However, this still leaves 7 betting sequences in each round that lead to a future round. By the fourth round of betting, this means that there are 343 possible betting sequences that could have led the players to this point, still 169 possible hands a player could have, and even more combinations of the five community cards. To even describe a strategy, you would need to determine what each player does in each one of these cases given all the information they have. Multiple approaches have been taken to combat this.<br />
<br />
The simplest was to use Selby’s pre-flop model as the strategy for pre-flop play, then solve the rest of the game round by round, in each round ignoring the implications of past betting. For example, if the pot has 4 big blinds at the start of the flop, the pre-flop action could have gone call-raise-call or raise-call, but the program does not take into account which player made the first raise. A better approach was to first solve a 3-round model where there is no betting on the river, and use whatever the optimal pre-flop strategy was for that game as the pre-flop strategy for the full game (which was found to give more accurate results than the Selby pre-flop model). Using that information, it is possible to compute the probability of the other player having a specific hand given that they bet in a certain way pre-flop. Given these constants, it is possible to formulate and run linear programs to determine an optimal strategy for the 3 rounds after and including the flop. Basically, this approach estimates the pre-flop strategy in a better way, and then is able to solve the rest of the game assuming both players follow that pre-flop strategy.<br />
<br />
The second important hurdle is the number of possible hands a player can have. Many people have attacked this with a technique called bucketing, which groups similar hands and plays those hands in the same way. One method of bucketing is to calculate, for each hand, the probability of winning (“hand strength"), and group hands based on that. However, this overlooks hands that have a high chance of improving on future rounds, like suited hands and connectors that have flush and straight draws. To measure this “hand potential," one can compute the probability of being behind during the current round but then ahead after the next one. One bucketing system that proved to be effective was choosing 5 or 6 buckets based on hand strength, and reserving one bucket for hands with high potential (like suited connectors).<br />
<br />
One thing to note with bucketing is that you have to do this for each round. For example, pre-flop you are putting 169 cards into buckets, but after the flop each pair of hole cards and flop is considered a different hand. This may suggest that using more buckets for future rounds may lead to more exact solutions, but in one paper they found that this did not affect the solutions that much. It also means that not only do you need to choose which hands are grouped together, you also need to compute the probabilities of transitioning from each pair of buckets to each pair of buckets in the next round (For example, we need to know the probability of player 1 having a hand in bucket 1 and player 2 having a hand in bucket 2 pre-flop, and then after the flop player 1 having a hand in bucket 2 and player 2 having a hand in bucket 2). This is another limitation on the number of buckets you can use, as using <span class="math inline">\(n\)</span> buckets for each round will require <span class="math inline">\(3n^4\)</span> probabilities to be calculated: <span class="math inline">\((n^2)^2\)</span> calculations for each of <span class="math inline">\(3\)</span> transitions between rounds.</p>
<h1 class="unnumbered" id="analysis-of-no-limit-tournament-games">Analysis of No-Limit Tournament Games</h1>
<p>In no-limit games, there are even more options than in limit games. However, it has been shown that, for “short-stacked" (low stack size) no-limit tournaments, “jam-fold" strategies (strategies where you either go all-in or fold) closely approximate optimal strategy (for one specific two-player no-limit tournament, it was found that either player could only add a maximum of .014 to their chances of winning by playing any strategy other than jam-fold.) So, this area, although seemingly a lot harder to analyze, has been explored as well, even in the three-player case.<br />
<br />
When analyzing tournament games, the player’s objectives are still to maximize their return, but their return is based on where they place (1st place, 2nd place, etc.) not based on how many chips they accumulate per hand. So, you have to know your probabilities of ending up in 1st place, 2nd place, etc. at all possible vectors of stack sizes for the players (for example, in a two player tournament with big blinds of 500 where each player starts at 2000 chips, the set of vectors of stack sizes (in chips) would be <span class="math inline">\(\{(0,4000),(250,3750),...(4000,0)\}\)</span>). This makes it so that you also have to consider things like the probabilities of transitioning from one vector of stack sizes to another after one hand, as this will determine your chances of eventually getting 1st place or 2nd place, which will affect your strategy, which will in turn affect the transition probabilities, etc.<br />
<br />
Thus, analysis of tournament games sometimes feature a “nested loop" approach, with an outer loop handling the stochastic part of the game (aka what was described in the previous paragraph, estimating the expected return for each player at each state), and an inner loop that updates each player’s optimal jam-fold strategy based on these probabilities. For a two-player game, the inner loop is basically just solving a linear programming problem for each state, while in a 3-player game other methods are required.<br />
<br />
One method for the inner loop of the 3-player game is called “fictitious play," a loop where, int the <span class="math inline">\(t^{th}\)</span> step of the loop, every player updates their strategy according to the following formula: <span class="math display">\[\text{New Strategy} =\]</span> <span class="math display">\[\frac{t - 1}{t} \cdot  \text{ Old Strategy } 
+ \frac{1}{t}  \cdot  \text {Best Response to Opponent&#39;s Old Strategy}\]</span> This is continued until no player can gains more than a pre-specified amount <span class="math inline">\(\epsilon\)</span> by changing their strategy (in other words, an <span class="math inline">\(\epsilon\)</span>-equilibrium has been reached). Although this algorithm is not guaranteed to end/converge, for tournament poker it did. So, the overall solution is to alternate between finding the strategies that lead to <span class="math inline">\(\epsilon\)</span>-equilibrium in each state, then updating the probabilities of each player winning at each state, repeating this until these probabilities change by less than a pre-specified amount <span class="math inline">\(\delta\)</span> from one iteration to the next.<br />
<br />
One thing to decide when using this approach is how to initialize the probabilities of each player winning at each state. For this, the “Independent Chip Model" (ICM) is used, which is a rule that says your probability of winning the tournament is approximately the proportion of your stack size to the sum of the stack sizes of all the players. For example, if player 1 had <span class="math inline">\(10\)</span> big blinds, player 2 had <span class="math inline">\(20\)</span>, and player 3 had <span class="math inline">\(30\)</span>, player 1 would have a <span class="math inline">\(\frac{10}{10+20+30} = \frac{1}{6}\)</span> chance of getting first and a <span class="math inline">\(\frac{20}{10+20+30} \cdot \frac{10}{10+30} + \frac{30}{10+20+30} \cdot \frac{10}{10+20} = \frac{1}{4}\)</span> chance of getting second (the first fraction covers the case where player 2 gets first, and the second one where player 3 gets first).<br />
<br />
Some interesting findings were that in the the two-player setting, the strategies for tournament games and just playing a single hand (restricted to jam-fold strategies) were very similar, while in a three-player game they were not. Similarly, the ICM is a very good model in the two-player case, meaning the final probabilities of each player winning at each stack vector did not change much from the initial values, while in the three-player game there are certain stack vectors where it was not a good model. Finally, there is no fixed ranking among poker hands, meaning that depending on your stack size, you may fold one hand and jam another, but do the opposite if your stack size is different.</p>
<h1 class="unnumbered" id="bibliography">Bibliography</h1>
<ol style="word-wrap: break-word;">
<li><p>https://en.wikipedia.org/wiki/Minimax<span class="math inline">\(\_\)</span>theorem</p></li>
<li><p>https://en.wikipedia.org/wiki/Dual<span class="math inline">\(\_\)</span>linear<span class="math inline">\(\_\)</span>program#: :text=The<span class="math inline">\(\%\)</span>20strong<span class="math inline">\(\%\)</span>20duality<span class="math inline">\(\%\)</span>20theorem<br />
<span class="math inline">\(\%\)</span>20states,of<span class="math inline">\(\%\)</span>20duality<span class="math inline">\(\%\)</span>20theorems<span class="math inline">\(\%\)</span>20in<span class="math inline">\(\%\)</span>20optimization.</p></li>
<li><p>http://www.archduke.org/simplex/art (Selby’s findings)</p></li>
<li><p>http://www.archduke.org/simplex/README (conversation about what he did)</p></li>
<li><p>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.69.3417&amp;rep=rep1&amp;type=pdf</p></li>
<li><p>https://www.cs.cmu.edu/ sandholm/3-player%20jam-fold.AAMAS08.pdf</p></li>
<li><p>https://poker.cs.ualberta.ca/publications/IJCAI03.pdf</p></li>
<li><p>https://webdocs.cs.ualberta.ca/ duane/publications/pdf/2002aij.pdf</p></li>
</ol>
</main>
</body>

<script>
var maxHeight = 0;

$(".row").each(function () {
    if ($(this).height() > maxHeight) {
        maxHeight = $(this).height();
    }
});

$(".row").height(maxHeight);
</script>


<footer class="blog-footer">
  <a href="https://us7.list-manage.com/contact-form?u=bd1a0a18ff760b00bf541b12d&form_id=b47981c22ebecdf4a32acfec1a5f0fc7">Contact Us</a> | <a href="https://docs.google.com/forms/d/e/1FAIpQLScARm0MoVGwxdH0w9PWmZNzjIf4CUJPzLcqDJ0UGob88ALIBg/viewform">Join Us</a><br>
Copyright © 2021 Math and CS Research.
</footer>
  </body>
</html>
</body><script src="https://code.jquery.com/jquery-3.4.1.slim.min.js" integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script></html>

